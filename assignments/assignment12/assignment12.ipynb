{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a112266",
   "metadata": {},
   "source": [
    "# Assignment 12 draft (NOT FINALIZED)\n",
    "\n",
    "Please fill in blanks in the *Answer* sections of this notebook. To check your answer for a problem, run the Setup, Answer, and Result sections. DO NOT MODIFY SETUP OR RESULT CELLS. See the [README](https://github.com/mortonne/datascipsych) for instructions on setting up a Python environment to run this notebook.\n",
    "\n",
    "Write your answers for each problem. Then restart the kernel, run all cells, and then save the notebook. Upload your notebook to Canvas.\n",
    "\n",
    "If you get stuck, read through the other notebooks in this directory, ask us for help in class, or ask other students for help in class or on the weekly discussion board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd9f8cc",
   "metadata": {},
   "source": [
    "## Problem: comparing two conditions (6 points)\n",
    "\n",
    "Given the recognition memory dataset (defined below) in `data`, test whether there is a difference in response between targets and lures.\n",
    "\n",
    "### Calculate means for each subject and condition (1 point)\n",
    "\n",
    "Calculate the mean response for each combination of subject and condition (target or lure). Assign the result to a variable called `mean_response_condition`.\n",
    "\n",
    "### Visualize means in each condition (1 point)\n",
    "\n",
    "Create a bar plot with error bars showing the mean response for targets and lures (0.5 points). Write a caption in a Markdown cell under the plot (0.5 points). Assign the output from Seaborn to a variable called `g1`.\n",
    "\n",
    "### Calculate summary statistics (1 point)\n",
    "\n",
    "Calculate the mean and SEM for the responses in the target and lure conditions. In the DataFrame with the statistics, there should be two columns named `mean` and `sem`. Assign the output to a variable called `stats_response_condition`.\n",
    "\n",
    "### Test for a significant difference (1 point)\n",
    "\n",
    "Use a paired t-test to test whether there is a significant difference in response between the target and lure conditions. Assign the result to a variable called `ttest_response_condition`.\n",
    "\n",
    "### Report the results (2 points)\n",
    "\n",
    "Write text describing the results. Report the mean and SEM for each condition, the results of the t-test, and your conclusion about whether there is an effect of condition on response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c119e6",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339b1849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject</th><th>trial</th><th>study_time</th><th>item_type</th><th>trial_type</th><th>response</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;subj01&quot;</td><td>1</td><td>1</td><td>&quot;word&quot;</td><td>&quot;target&quot;</td><td>1</td></tr><tr><td>&quot;subj01&quot;</td><td>2</td><td>1</td><td>&quot;word&quot;</td><td>&quot;target&quot;</td><td>1</td></tr><tr><td>&quot;subj01&quot;</td><td>3</td><td>1</td><td>&quot;word&quot;</td><td>&quot;target&quot;</td><td>1</td></tr><tr><td>&quot;subj01&quot;</td><td>4</td><td>1</td><td>&quot;word&quot;</td><td>&quot;target&quot;</td><td>1</td></tr><tr><td>&quot;subj01&quot;</td><td>5</td><td>1</td><td>&quot;word&quot;</td><td>&quot;target&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌─────────┬───────┬────────────┬───────────┬────────────┬──────────┐\n",
       "│ subject ┆ trial ┆ study_time ┆ item_type ┆ trial_type ┆ response │\n",
       "│ ---     ┆ ---   ┆ ---        ┆ ---       ┆ ---        ┆ ---      │\n",
       "│ str     ┆ i64   ┆ i64        ┆ str       ┆ str        ┆ i64      │\n",
       "╞═════════╪═══════╪════════════╪═══════════╪════════════╪══════════╡\n",
       "│ subj01  ┆ 1     ┆ 1          ┆ word      ┆ target     ┆ 1        │\n",
       "│ subj01  ┆ 2     ┆ 1          ┆ word      ┆ target     ┆ 1        │\n",
       "│ subj01  ┆ 3     ┆ 1          ┆ word      ┆ target     ┆ 1        │\n",
       "│ subj01  ┆ 4     ┆ 1          ┆ word      ┆ target     ┆ 1        │\n",
       "│ subj01  ┆ 5     ┆ 1          ┆ word      ┆ target     ┆ 1        │\n",
       "└─────────┴───────┴────────────┴───────────┴────────────┴──────────┘"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "from IPython.display import display\n",
    "data = pl.read_csv(\"gen_recog2.csv\")\n",
    "mean_response_condition = None\n",
    "g1 = None\n",
    "stats_response_condition = None\n",
    "ttest_response_condition = None\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6764b",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34303c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba719d",
   "metadata": {},
   "source": [
    "> Please describe your results below.\n",
    "\n",
    "[answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2ae82",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ddb49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [mean_response_condition, g1, stats_response_condition, ttest_response_condition]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    display(mean_response_condition.sort(\"subject\", \"trial_type\"))\n",
    "    print(g1)\n",
    "    display(stats_response_condition.sort(\"trial_type\"))\n",
    "    display(ttest_response_condition)\n",
    "    \n",
    "    # this should not throw any errors\n",
    "    assert all(c in mean_response_condition.columns for c in [\"subject\", \"trial_type\", \"response\"])\n",
    "    assert mean_response_condition.shape == (60, 3)\n",
    "    assert isinstance(g1, sns.FacetGrid)\n",
    "    assert stats_response_condition[\"mean\"].round(3).equals(pl.Series([0.374, 0.611]))\n",
    "    assert stats_response_condition[\"sem\"].round(3).equals(pl.Series([0.013, 0.015]))\n",
    "    assert round(ttest_response_condition.loc[\"T-test\", \"T\"], 3) == 11.354\n",
    "    assert ttest_response_condition.loc[\"T-test\", \"dof\"] == 29\n",
    "    assert ttest_response_condition.loc[\"T-test\", \"alternative\"] == \"two-sided\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascipsych",
   "language": "python",
   "name": "datascipsych"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
