{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9 draft (NOT FINALIZED)\n",
    "\n",
    "Please fill in blanks in the *Answer* sections of this notebook. To check your answer for a problem, run the Setup, Answer, and Result sections. DO NOT MODIFY SETUP OR RESULT CELLS. See the [README](https://github.com/mortonne/datascipsych) for instructions on setting up a Python environment to run this notebook.\n",
    "\n",
    "Write your answers for each problem. Then restart the kernel, run all cells, and then save the notebook. Upload your notebook to Canvas.\n",
    "\n",
    "If you get stuck, read through the other notebooks in this directory, ask us for help in class, or ask other students for help in class or on the weekly discussion board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: working with null values (2 points)\n",
    "\n",
    "### Read a file with null values (1 point)\n",
    "\n",
    "Read the `study.csv` file in this directory using `pl.read_csv`. Use the optional `null_values` input to treat `n/a` entries as null. Assign the DataFrame to a variable called `study`.\n",
    "\n",
    "### Check the number of null values (1 point)\n",
    "\n",
    "Use a Polars function to get the number of null values in the `response` column and assign it to a variable called `null_responses`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from IPython.display import display\n",
    "study = None\n",
    "null_responses = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [study, null_responses]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    with pl.Config(tbl_rows=50):\n",
    "        display(study)\n",
    "    print(null_responses)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    assert null_responses == 2\n",
    "    response = pl.Series(\n",
    "        [1, 0, 1, 0, 1, 0, None, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, None, 1, 1, 0, 0, 1]\n",
    "    )\n",
    "    assert study[\"response\"].equals(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: recoding variables (2 points)\n",
    "\n",
    "Take the `data` DataFrame (defined below) and recode the `item_type` column. Replace that column with a version where `1` is now `\"word\"` and `2` is now `\"picture\"`. Assign the result to a variable called `recoded`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_csv(\"study.csv\")\n",
    "recoded = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [recoded]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    with pl.Config(tbl_rows=50):\n",
    "        display(recoded)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    item_type = pl.Series(\n",
    "        [\n",
    "            \"word\", \n",
    "            \"picture\", \n",
    "            \"picture\", \n",
    "            \"word\", \n",
    "            \"picture\", \n",
    "            \"word\", \n",
    "            \"word\", \n",
    "            \"picture\", \n",
    "            \"picture\", \n",
    "            \"word\", \n",
    "            \"word\", \n",
    "            \"picture\", \n",
    "            \"word\", \n",
    "            \"word\",\n",
    "            \"picture\",\n",
    "            \"picture\",\n",
    "            \"word\",\n",
    "            \"word\",\n",
    "            \"picture\",\n",
    "            \"picture\",\n",
    "            \"picture\",\n",
    "            \"picture\",\n",
    "            \"word\",\n",
    "            \"word\",\n",
    "        ]\n",
    "    )\n",
    "    assert recoded[\"item_type\"].equals(item_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: grouping and aggregation (2 points)\n",
    "\n",
    "### One set of groups (1 point)\n",
    "\n",
    "Take the `data` DataFrame (defined below) and use `group_by` and `agg` to calculate the mean response time for targets and lures. Assign the result to a variable called `rt_trial_type`.\n",
    "\n",
    "### Two sets of groups (1 point)\n",
    "\n",
    "Take the `data` DataFrame (defined below) and use `group_by` and `agg` to calculate the mean response time for targets and lures, split by whether the response was `\"yes\"` or `\"no\"`. Assign the result to a variable called `rt_trial_type_response`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    pl.read_csv(\"study.csv\", null_values=\"n/a\")\n",
    "    .with_columns(pl.col(\"response\").cast(pl.String).replace({\"0\": \"no\", \"1\": \"yes\"}))\n",
    "    .filter(pl.col(\"response\").is_not_null())\n",
    ")\n",
    "rt_trial_type = None\n",
    "rt_trial_type_response = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [rt_trial_type, rt_trial_type_response]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    display(rt_trial_type)\n",
    "    display(rt_trial_type_response)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    assert rt_trial_type.sort(\"trial_type\")[\"response_time\"].round(2).equals(pl.Series([2.26, 1.64]))\n",
    "    assert rt_trial_type_response.sort(\"trial_type\", \"response\")[\"response_time\"].round(2).equals(pl.Series([2.37, 2.14, 1.85, 1.59]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: reshaping data to long format (2 points)\n",
    "\n",
    "In the `scores.csv` dataset, there were two experimental conditions (1 or 2) and three tests of performance (test 1, test 2, and test 3). The spreadsheet has a column for each test. Say we want to reshape the data into long format, with one observation per row.\n",
    "\n",
    "Take the `scores` DataFrame defined and reshape it to long format. There should be 12 rows and 4 columns: `participant_id`, `condition`, `test_type`, and `test_score`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pl.read_csv(\"scores.csv\")\n",
    "long = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [long]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    display(long)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    sorted = long.sort(\"test_type\", \"participant_id\", \"condition\")\n",
    "    assert sorted[\"participant_id\"].equals(pl.Series([1, 1, 2, 2, 1, 1, 2, 2]))\n",
    "    assert sorted[\"condition\"].equals(pl.Series([1, 2, 1, 2, 1, 2, 1, 2]))\n",
    "    assert sorted[\"test_type\"].equals(\n",
    "        pl.Series(\n",
    "            [\"test1\", \"test1\", \"test1\", \"test1\", \"test2\", \"test2\", \"test2\", \"test2\"]\n",
    "        )\n",
    "    )\n",
    "    assert sorted[\"test_score\"].equals(pl.Series([6, 4, 9, 7, 9, 8, 10, 9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: reshaping data to wide format (2 points)\n",
    "\n",
    "In the `study.csv` data, the item type was either 1 (word) or 2 (picture). Say that we want to know whether there was an average difference in response time for these two types of items.\n",
    "\n",
    "### Reshape data (1 point)\n",
    "\n",
    "Given the `rt` DataFrame defined below, \"pivot\" the data into wide format using the `pivot` function. The resulting DataFrame should have one row per participant, with columns: `participant_id`, `1` (the mean response time for item type 1 for each participant), and `2` (the mean response time for item type 2 for each participant). Assign the result to a variable called `wide`.\n",
    "\n",
    "### Calculate response time difference (1 point)\n",
    "\n",
    "Use `with_columns` to modify your `wide` DataFrame by adding a new column called `rt_diff`, which has the difference between response time for item type 2 and item type 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = (\n",
    "    pl.read_csv(\"study.csv\", null_values=\"n/a\")\n",
    "    .group_by(pl.col(\"participant_id\", \"item_type\"))\n",
    "    .agg(pl.col(\"response_time\").mean())\n",
    "    .sort(\"participant_id\", \"item_type\")\n",
    ")\n",
    "wide = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [wide]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    display(wide)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    assert wide[\"participant_id\"].equals(pl.Series([1, 2, 3]))\n",
    "    assert wide[\"1\"].round(2).equals(pl.Series([1.97, 1.70, 2.13]))\n",
    "    assert wide[\"2\"].round(2).equals(pl.Series([1.85, 1.85, 2.30]))\n",
    "    assert wide[\"rt_diff\"].round(2).equals(pl.Series([-0.12, 0.15, 0.17]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascipsych",
   "language": "python",
   "name": "datascipsych"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
